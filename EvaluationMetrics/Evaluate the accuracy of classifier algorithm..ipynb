{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file we'll observe, how spliting the dataset into testing and training sets can affect the performance of various classification algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Titanic dataset from Kaggle will be used as a dataset ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier algorithms used:\n",
    "\n",
    "- Decision tree algorithm\n",
    "- Gaussian Naive Bayes algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#importing all essential libraries \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score # to predict the accuracy of the prediction of given algorithm\n",
    "from sklearn.naive_bayes import GaussianNB #it is importing Gaussian naive bayes classifier\n",
    "from sklearn import cross_validation # this is used to split our dataset into training and testing sets\n",
    "from sklearn import datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading the dataset into X,the input paramter\n",
    "X = pd.read_csv('titanic_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#remove all unnecessary features and retain only features with numerical values\n",
    "X = X._get_numeric_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#defining our output variable ie y\n",
    "y = X['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#removing few more features from dataset\n",
    "del X['Age'] # because it has a lot of missing values \n",
    "del X['Survived'] # because it's a output and it shouldn't be included in input paramter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#it's time to split the data:\n",
    "X_train,X_test,y_train,y_test = cross_validation.train_test_split(X,y,test_size = 0.4,random_state = 0)\n",
    "#here 40% of data is retained for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree has an accuracy : 0.663865546218\n"
     ]
    }
   ],
   "source": [
    "#let's trian our classifiers:\n",
    "\n",
    "#Decision tree classifier(DTC):\n",
    "clf1 = DecisionTreeClassifier() # defining DTC as clf1\n",
    "clf1.fit(X_train,y_train) # training our classifier with training data sets\n",
    "print \"Decision Tree has an accuracy :\",accuracy_score(y_test,clf1.predict(X_test))\n",
    "\n",
    "#in the above line first we'll be predicting the y' value for X_test with clf1.predict(X_test)\n",
    "#then compare that y' with actual y and compute the accuracy of classifier using accuracy_score()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB has an accuracy : 0.672268907563\n"
     ]
    }
   ],
   "source": [
    "#Next is Gaussian Naive Bayes classifier, here also the procedure is\n",
    "#similar to Decision tree except that the classifier we use here is GaussianNB\n",
    "\n",
    "clf2 = GaussianNB() \n",
    "clf2.fit(X_train,y_train) \n",
    "print \"GaussianNB has an accuracy :\",accuracy_score(y_test,clf2.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#####  Confusion matrix\n",
    "let's use confusion matrix as an evaluation metrics to  measure accuracy of  Decision tree & GaussianNB algorithm.(Instead of accuracy_score() which was used earlier)\n",
    "\n",
    "the confusion matrix has the following order\n",
    "\n",
    "True Negative ,  False Positive\n",
    "\n",
    "False Negative , True Positive\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree has a confusion matrix \n",
      ": [[160  61]\n",
      " [ 69  67]]\n"
     ]
    }
   ],
   "source": [
    "#let's trian our classifiers:\n",
    "\n",
    "#Decision tree classifier(DTC):\n",
    "clf1 = DecisionTreeClassifier() # defining DTC as clf1\n",
    "clf1.fit(X_train,y_train) # training our classifier with training data sets\n",
    "print \"Decision Tree has a confusion matrix \\n:\",confusion_matrix(y_test,clf1.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB has a confusion matrix \n",
      ": [[188  33]\n",
      " [ 84  52]]\n"
     ]
    }
   ],
   "source": [
    "#Next is Gaussian Naive Bayes classifier\n",
    "clf2 = GaussianNB() \n",
    "clf2.fit(X_train,y_train) \n",
    "print \"GaussianNB has a confusion matrix \\n:\",confusion_matrix(y_test,clf2.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precision and recall of a confusion matrix\n",
    "Let's find the precision and recall for Decision tree and GaussianNB classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Recall: 0.50 and precision : 0.58\n"
     ]
    }
   ],
   "source": [
    "#Decision tree classifier(DTC):\n",
    "from sklearn.metrics import recall_score as recall\n",
    "from sklearn.metrics import precision_score as precision\n",
    "\n",
    "clf = DecisionTreeClassifier() # defining DTC as clf1\n",
    "clf.fit(X_train,y_train) # training our classifier with training data sets\n",
    "\n",
    "print \"Decision Tree Recall: {:.2f} and precision : {:.2f}\".format(recall(y_test,clf.predict(X_test)),precision(y_test,clf.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussiaNB recall: 0.38 and precision : 0.61\n"
     ]
    }
   ],
   "source": [
    "#Next is Gaussian Naive Bayes classifier\n",
    "\n",
    "clf = GaussianNB() # defining DTC as clf1\n",
    "clf.fit(X_train,y_train) # training our classifier with training data sets\n",
    "\n",
    "print \"GaussiaNB recall: {:.2f} and precision : {:.2f}\".format(recall(y_test,clf.predict(X_test)),precision(y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### F1 Score\n",
    "Now that you've seen precision and recall, another metric you might consider using is the F1 score. F1 score combines precision and recall relative to a specific positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree f1 score: 0.53\n"
     ]
    }
   ],
   "source": [
    "#Decision tree classifier(DTC):\n",
    "from sklearn.metrics import recall_score as recall\n",
    "from sklearn.metrics import precision_score as precision\n",
    "from sklearn.metrics import f1_score\n",
    "clf = DecisionTreeClassifier() # defining DTC as clf1\n",
    "clf.fit(X_train,y_train) # training our classifier with training data sets\n",
    "\n",
    "print \"Decision Tree f1 score: {:.2f}\".format(f1_score(y_test,clf.predict(X_test)),f1_score(y_test,clf.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussiaNB f1 score: 0.47\n"
     ]
    }
   ],
   "source": [
    "#Next is Gaussian Naive Bayes classifier\n",
    "\n",
    "clf = GaussianNB() # defining DTC as clf1\n",
    "clf.fit(X_train,y_train) # training our classifier with training data sets\n",
    "\n",
    "print \"GaussiaNB f1 score: {:.2f}\".format(f1_score(y_test,clf.predict(X_test)),f1_score(y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
